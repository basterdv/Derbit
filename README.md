deribit_tracker/
├── app/
│   ├── main.py          # FastAPI приложение и эндпоинты
│   ├── database.py      # Модели и подключение к БД
│   ├── celery_app.py    # Конфигурация Celery
│   └── tasks.py         # Задача на получение цен
├── docker-compose.yml
├── Dockerfile
├── requirements.txt
└── README.md

В секции Design Decisions следует указать:
Выбор Celery Beat: Использование Celery Beat вместо бесконечного цикла while True гарантирует отказоустойчивость и возможность масштабирования задач по расписанию.
Тип Timestamp: Хранение в формате BigInteger (UNIX timestamp) в БД для упрощения фильтрации и экономии места, вместо строковых дат.
Архитектура БД: Использование одной таблицы с индексами по полям ticker и timestamp для обеспечения высокой скорости выполнения GET-запросов.
Разделение ответственности: API и Worker (Celery) запускаются в разных контейнерах, что позволяет масштабировать их независимо друг от друга.
6. Инструкция по развертыванию
Клонировать репозиторий.
Создать .env файл с параметрами подключения к PostgreSQL.
Запустить проект командой docker-compose up --build.
Документация Swagger будет доступна по адресу http://localhost:8000/docs.
Полный исходный код и Docker-конфигурация должны быть выложены на GitLab в соответствии с требованиями.
Оформление Design Decisions (для README)
В 2026 году стандарт оформления технических решений требует четкой аргументации. Добавьте это в README:
Database: PostgreSQL выбран как надежное реляционное хранилище с поддержкой индексации по времени (B-tree индекс на timestamp критически важен для производительности метода /filter).
Task Management: Celery используется совместно с Redis для обеспечения отказоустойчивости. Даже если биржа временно недоступна, Celery повторит попытку (retry), что гарантирует непрерывность данных.
API Design: Использование Depends(get_db) обеспечивает эффективное управление пулом соединений (connection pooling), закрывая сессии сразу после выполнения запроса.

Design Decisions (дополнение для README):
Асинхронность (aiohttp): В 2026 году использование aiohttp вместо requests является предпочтительным для высокопроизводительных систем. Это позволяет выполнять запросы ко всем тикерам одновременно (параллельно), а не последовательно, что минимизирует задержку между получением цен разных валют.
Прокси: Использование BasicAuth в aiohttp обеспечивает безопасную передачу учетных данных прокси.
Интеграция с Celery: Использование asyncio.run() внутри shared_task — это стандартный паттерн для запуска асинхронного кода в синхронном воркере Celery.

celery -A app.celery_app beat --loglevel=info 
celery -A app.celery_app worker --loglevel=info
python.exe -m uvicorn app.main:app --reload   
wsl
sudo service redis-server start



